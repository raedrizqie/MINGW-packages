diff --git a/src/3rdparty/chromium/tools/grit/grit/tool/build.py b/src/3rdparty/chromium/tools/grit/grit/tool/build.py
index 1b41e9a..8de1345 100644
--- a/src/3rdparty/chromium/tools/grit/grit/tool/build.py
+++ b/src/3rdparty/chromium/tools/grit/grit/tool/build.py
@@ -364,6 +364,10 @@ are exported to translation interchange files (e.g. XMB files), etc.
                        'chrome_messages_json_gzip', 'policy_templates'):
       return 'utf_8'
     # TODO(gfeher) modify here to set utf-8 encoding for admx/adml
+    if sys.platform == 'win32' and 'MINGW' in sys.version:
+      # windres cannot handle utf-16 encoding
+      if output_type == 'rc_all':
+        return 'utf_8'
     return 'utf_16'
 
   def Process(self):
diff --git a/src/3rdparty/chromium/tools/grit/grit/tool/update_resource_ids/assigner.py b/src/3rdparty/chromium/tools/grit/grit/tool/update_resource_ids/assigner.py
index 6cd4603..7527d65 100644
--- a/src/3rdparty/chromium/tools/grit/grit/tool/update_resource_ids/assigner.py
+++ b/src/3rdparty/chromium/tools/grit/grit/tool/update_resource_ids/assigner.py
@@ -93,7 +93,7 @@ class NaiveCoarseIdAssigner(BaseCoarseIdAssigner):
 
 
 class DagCoarseIdAssigner(BaseCoarseIdAssigner):
-  """CoarseIdAssigner that preserves existing structure.
+  r"""CoarseIdAssigner that preserves existing structure.
 
 Start ID assignment in resource_ids is structured a Series-Parallel Graph, which
 is a directed, acyclic multi-graph generated by the following:
diff --git a/src/3rdparty/chromium/tools/grit/grit/util.py b/src/3rdparty/chromium/tools/grit/grit/util.py
index 6e8cdb0..09cd590 100644
--- a/src/3rdparty/chromium/tools/grit/grit/util.py
+++ b/src/3rdparty/chromium/tools/grit/grit/util.py
@@ -8,6 +8,7 @@
 from __future__ import print_function
 
 import codecs
+import html.entities
 import io
 import os
 import re
@@ -16,10 +17,6 @@ import sys
 import tempfile
 from xml.sax import saxutils
 
-import six
-from six import StringIO
-from six.moves import html_entities as entities
-
 from grit import lazy_re
 
 _root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
@@ -212,8 +209,9 @@ def ReadFile(filename, encoding):
     encoding = None
   else:
     mode = 'r'
+    encoding = 'utf-8'
 
-  with io.open(abs(filename), mode, encoding=encoding) as f:
+  with open(abs(filename), mode, encoding=encoding) as f:
     return f.read()
 
 
@@ -226,7 +224,7 @@ def WrapOutputStream(stream, encoding = 'utf-8'):
 def ChangeStdoutEncoding(encoding = 'utf-8'):
   '''Changes STDOUT to print characters using the specified encoding.'''
   # If we're unittesting, don't reconfigure.
-  if isinstance(sys.stdout, StringIO):
+  if isinstance(sys.stdout, io.StringIO):
     return
 
   if sys.version_info.major < 3:
@@ -272,16 +270,16 @@ def UnescapeHtml(text, replace_nbsp=True):
   def Replace(match):
     groups = match.groupdict()
     if groups['hex']:
-      return six.unichr(int(groups['hex'], 16))
+      return chr(int(groups['hex'], 16))
     elif groups['decimal']:
-      return six.unichr(int(groups['decimal'], 10))
+      return chr(int(groups['decimal'], 10))
     else:
       name = groups['named']
       if name == 'nbsp' and not replace_nbsp:
         return match.group()  # Don't replace &nbsp;
       assert name != None
-      if name in entities.name2codepoint:
-        return six.unichr(entities.name2codepoint[name])
+      if name in html.entities.name2codepoint:
+        return chr(html.entities.name2codepoint[name])
       else:
         return match.group()  # Unknown HTML character entity - don't replace
 
@@ -349,7 +347,7 @@ def ParseGrdForUnittest(body, base_dir=None, predetermined_ids_file=None,
     base_dir: The base_dir attribute of the <grit> tag.
   '''
   from grit import grd_reader
-  if isinstance(body, six.text_type):
+  if isinstance(body, str):
     body = body.encode('utf-8')
   if base_dir is None:
     base_dir = PathFromRoot('.')
diff --git a/src/3rdparty/chromium/tools/json_schema_compiler/feature_compiler.py b/src/3rdparty/chromium/tools/json_schema_compiler/feature_compiler.py
index 1480390..c68e007 100644
--- a/src/3rdparty/chromium/tools/json_schema_compiler/feature_compiler.py
+++ b/src/3rdparty/chromium/tools/json_schema_compiler/feature_compiler.py
@@ -371,8 +371,8 @@ def DoesNotHaveAllowlistForHostedApps(value):
   # what the allowlist looks like) to a python list of strings.
   def cpp_list_to_list(cpp_list):
     assert type(cpp_list) is str
-    assert cpp_list[0] is '{'
-    assert cpp_list[-1] is '}'
+    assert cpp_list[0] == '{'
+    assert cpp_list[-1] == '}'
     new_list = json.loads('[%s]' % cpp_list[1:-1])
     assert type(new_list) is list
     return new_list
diff --git a/src/3rdparty/chromium/tools/json_schema_compiler/model.py b/src/3rdparty/chromium/tools/json_schema_compiler/model.py
index cfd6fbd..ea81973 100644
--- a/src/3rdparty/chromium/tools/json_schema_compiler/model.py
+++ b/src/3rdparty/chromium/tools/json_schema_compiler/model.py
@@ -208,7 +208,7 @@ class Type(object):
     self.name = name
 
     # The typename "ManifestKeys" is reserved.
-    if name is 'ManifestKeys':
+    if name == 'ManifestKeys':
       assert parent == namespace and input_origin.from_manifest_keys, \
           'ManifestKeys type is reserved'
 
diff --git a/src/3rdparty/chromium/tools/metrics/actions/extract_actions.py b/src/3rdparty/chromium/tools/metrics/actions/extract_actions.py
index 11982d5..404d1f1 100755
--- a/src/3rdparty/chromium/tools/metrics/actions/extract_actions.py
+++ b/src/3rdparty/chromium/tools/metrics/actions/extract_actions.py
@@ -25,7 +25,6 @@ from __future__ import print_function
 
 __author__ = 'evanm (Evan Martin)'
 
-from HTMLParser import HTMLParser
 import logging
 import os
 import re
@@ -33,6 +32,11 @@ import shutil
 import sys
 from xml.dom import minidom
 
+if sys.version_info.major == 2:
+  from HTMLParser import HTMLParser
+else:
+  from html.parser import HTMLParser
+
 import action_utils
 import actions_model
 
@@ -365,21 +369,21 @@ def GrepForActions(path, actions):
   else:
     action_re = USER_METRICS_ACTION_RE
 
-  finder = ActionNameFinder(path, open(path).read(), action_re)
+  finder = ActionNameFinder(path, open(path, encoding='utf-8').read(), action_re)
   while True:
     try:
       action_name = finder.FindNextAction()
       if not action_name:
         break
       actions.add(action_name)
-    except InvalidStatementException, e:
+    except InvalidStatementException as e:
       logging.warning(str(e))
 
   if action_re != USER_METRICS_ACTION_RE:
     return
 
   line_number = 0
-  for line in open(path):
+  for line in open(path, encoding='utf-8'):
     line_number = line_number + 1
     if COMPUTED_ACTION_RE.search(line):
       # Warn if this file shouldn't be calling RecordComputedAction.
@@ -434,12 +438,12 @@ def GrepForWebUIActions(path, actions):
   close_called = False
   try:
     parser = WebUIActionsParser(actions)
-    parser.feed(open(path).read())
+    parser.feed(open(path, encoding='utf-8').read())
     # An exception can be thrown by parser.close(), so do it in the try to
     # ensure the path of the file being parsed gets printed if that happens.
     close_called = True
     parser.close()
-  except Exception, e:
+  except Exception as e:
     print("Error encountered for path %s" % path)
     raise e
   finally:
@@ -460,7 +464,7 @@ def GrepForDevToolsActions(path, actions):
   if ext != '.js':
     return
 
-  finder = ActionNameFinder(path, open(path).read(),
+  finder = ActionNameFinder(path, open(path, encoding='utf-8').read(),
       USER_METRICS_ACTION_RE_DEVTOOLS)
   while True:
     try:
@@ -468,7 +472,7 @@ def GrepForDevToolsActions(path, actions):
       if not action_name:
         break
       actions.add(action_name)
-    except InvalidStatementException, e:
+    except InvalidStatementException as e:
       logging.warning(str(e))
 
 def WalkDirectory(root_path, actions, extensions, callback):
diff --git a/src/3rdparty/chromium/tools/metrics/common/diff_util.py b/src/3rdparty/chromium/tools/metrics/common/diff_util.py
index def7e2d..2b58e92 100644
--- a/src/3rdparty/chromium/tools/metrics/common/diff_util.py
+++ b/src/3rdparty/chromium/tools/metrics/common/diff_util.py
@@ -10,6 +10,7 @@ from __future__ import print_function
 
 import logging
 import os
+import sys
 import webbrowser
 
 from difflib import HtmlDiff
@@ -38,11 +39,15 @@ def PromptUserToAcceptDiff(old_text, new_text, prompt):
       todesc='Updated', context=True, numlines=5)
   temp = NamedTemporaryFile(suffix='.html', delete=False)
   try:
+    html_diff = html_diff.encode('utf-8')
     temp.write(html_diff)
     temp.close()  # Close the file so the browser process can access it.
     webbrowser.open('file://' + temp.name)
     print(prompt)
-    response = raw_input('(Y/n): ').strip().lower()
+    if sys.version_info.major == 2:
+      response = raw_input('(Y/n): ').strip().lower()
+    else:
+      response = input('(Y/n): ').strip().lower()
   finally:
     temp.close()  # May be called on already closed file.
     os.remove(temp.name)
diff --git a/src/3rdparty/chromium/tools/metrics/common/etree_util.py b/src/3rdparty/chromium/tools/metrics/common/etree_util.py
index cbfcbe8..2712078 100644
--- a/src/3rdparty/chromium/tools/metrics/common/etree_util.py
+++ b/src/3rdparty/chromium/tools/metrics/common/etree_util.py
@@ -4,6 +4,7 @@
 
 """Utility functions for parsing XML strings into ElementTree nodes."""
 
+import sys
 import xml.etree.ElementTree as ET
 import xml.sax
 
@@ -68,7 +69,7 @@ def GetTopLevelContent(file_content):
   first_tag_line = 0
   first_tag_column = 0
   try:
-    xml.sax.parseString(file_content, handler)
+    xml.sax.parseString(file_content.encode('utf-8'), handler)
   except _FirstTagFoundError:
     # This is the expected case, it means a tag was found in the doc.
     first_tag_line = handler.GetFirstTagLine()
@@ -91,4 +92,14 @@ def GetTopLevelContent(file_content):
 
 def ParseXMLString(raw_xml):
   """Parses raw_xml and returns an ElementTree node that includes comments."""
-  return ET.fromstring(raw_xml, _CommentedXMLParser())
+  if sys.version_info.major == 2:
+    return ET.fromstring(raw_xml.encode('utf-8'), _CommentedXMLParser())
+  else:
+    if sys.version_info >= (3, 8, 0):
+      tree_builder = ET.TreeBuilder(insert_comments=True)
+    else:
+      # Print a warning if running with an old Py3 version (e.g macOS default).
+      print('Warning: Python < 3.8 detected, comments will be stripped.')
+      print('Consider running with depot_tools/python-bin/python3 instead.')
+      tree_builder = ET.TreeBuilder()
+    return ET.fromstring(raw_xml, ET.XMLParser(target=tree_builder))
diff --git a/src/3rdparty/chromium/tools/metrics/common/models.py b/src/3rdparty/chromium/tools/metrics/common/models.py
index 625bbe2..02440aa 100644
--- a/src/3rdparty/chromium/tools/metrics/common/models.py
+++ b/src/3rdparty/chromium/tools/metrics/common/models.py
@@ -244,7 +244,7 @@ class ChildType(object):
 
 
 class ObjectNodeType(NodeType):
-  """A complex node type that has attributes or other nodes as children.
+  r"""A complex node type that has attributes or other nodes as children.
 
   Unmarshalls nodes to objects.
 
diff --git a/src/3rdparty/chromium/tools/metrics/ukm/ukm_model.py b/src/3rdparty/chromium/tools/metrics/ukm/ukm_model.py
index 57decab..45cb21e 100644
--- a/src/3rdparty/chromium/tools/metrics/ukm/ukm_model.py
+++ b/src/3rdparty/chromium/tools/metrics/ukm/ukm_model.py
@@ -72,7 +72,7 @@ _AGGREGATION_TYPE =  models.ObjectNodeType(
 _METRIC_TYPE =  models.ObjectNodeType(
     'metric',
     attributes=[
-      ('name', str, r'^[A-Za-z0-9_.]+$'),
+      ('name', str, r'^[A-Za-z][A-Za-z0-9_.]*$'),
       ('semantic_type', str, None),
       ('enum', str, None),
     ],
@@ -93,7 +93,7 @@ _METRIC_TYPE =  models.ObjectNodeType(
 _EVENT_TYPE =  models.ObjectNodeType(
     'event',
     attributes=[
-      ('name', str, r'^[A-Za-z0-9.]+$'),
+      ('name', str, r'^[A-Za-z][A-Za-z0-9.]*$'),
       ('singular', str, r'(?i)^(|true|false)$'),
     ],
     alphabetization=[
diff --git a/src/3rdparty/chromium/tools/perf/chrome_telemetry_build/BUILD.gn b/src/3rdparty/chromium/tools/perf/chrome_telemetry_build/BUILD.gn
index 280bb75..3733d3f 100644
--- a/src/3rdparty/chromium/tools/perf/chrome_telemetry_build/BUILD.gn
+++ b/src/3rdparty/chromium/tools/perf/chrome_telemetry_build/BUILD.gn
@@ -39,7 +39,7 @@ group("telemetry_chrome_test") {
     data_deps += [ "//chrome" ]
   }
 
-  if (is_win) {
+  if (is_msvc) {
     data_deps += [ "//chrome:reorder_imports" ]
   }
 
@@ -77,6 +77,9 @@ group("telemetry_chrome_test") {
       "//build/win:copy_cdb_to_output",
       "//third_party/crashpad/crashpad/tools:crashpad_database_util",
     ]
+    if (is_mingw) {
+      data_deps -= [ "//build/win:copy_cdb_to_output" ]
+    }
   }
 }
 
diff --git a/src/3rdparty/chromium/tools/polymer/polymer.py b/src/3rdparty/chromium/tools/polymer/polymer.py
index 2bc049f..ca53d43 100644
--- a/src/3rdparty/chromium/tools/polymer/polymer.py
+++ b/src/3rdparty/chromium/tools/polymer/polymer.py
@@ -198,7 +198,7 @@ def _generate_js_imports(html_file):
   imports_start_offset = -1
   imports_end_index = -1
   imports_found = False
-  with io.open(html_file, encoding='utf-8', mode='r') as f:
+  with open(html_file, encoding='utf-8', mode='r') as f:
     lines = f.readlines()
     for i, line in enumerate(lines):
       match = re.search(r'\s*<link rel="import" href="(.*)"', line)
@@ -240,7 +240,7 @@ def _generate_js_imports(html_file):
 
 
 def _extract_dom_module_id(html_file):
-  with io.open(html_file, encoding='utf-8', mode='r') as f:
+  with open(html_file, encoding='utf-8', mode='r') as f:
     contents = f.read()
     match = re.search(r'\s*<dom-module id="(.*)"', contents)
     assert match
@@ -254,12 +254,12 @@ def _add_template_markers(html_template):
 
 def _extract_template(html_file, html_type):
   if html_type == 'v3-ready':
-    with io.open(html_file, encoding='utf-8', mode='r') as f:
+    with open(html_file, encoding='utf-8', mode='r') as f:
       template = f.read()
       return _add_template_markers('\n' + template)
 
   if html_type == 'dom-module':
-    with io.open(html_file, encoding='utf-8', mode='r') as f:
+    with open(html_file, encoding='utf-8', mode='r') as f:
       lines = f.readlines()
       start_line = -1
       end_line = -1
@@ -286,7 +286,7 @@ def _extract_template(html_file, html_type):
     return _add_template_markers('\n' + ''.join(lines[start_line:end_line + 1]))
 
   if html_type == 'style-module':
-    with io.open(html_file, encoding='utf-8', mode='r') as f:
+    with open(html_file, encoding='utf-8', mode='r') as f:
       lines = f.readlines()
       start_line = -1
       end_line = -1
@@ -306,7 +306,7 @@ def _extract_template(html_file, html_type):
 
   if html_type == 'iron-iconset':
     templates = []
-    with io.open(html_file, encoding='utf-8', mode='r') as f:
+    with open(html_file, encoding='utf-8', mode='r') as f:
       lines = f.readlines()
       start_line = -1
       end_line = -1
@@ -327,7 +327,7 @@ def _extract_template(html_file, html_type):
 
 
   assert html_type == 'custom-style'
-  with io.open(html_file, encoding='utf-8', mode='r') as f:
+  with open(html_file, encoding='utf-8', mode='r') as f:
     lines = f.readlines()
     start_line = -1
     end_line = -1
@@ -356,7 +356,7 @@ def process_v3_ready(js_file, html_file):
   # Extract HTML template and place in JS file.
   html_template = _extract_template(html_file, 'v3-ready')
 
-  with io.open(js_file, encoding='utf-8') as f:
+  with open(js_file, encoding='utf-8') as f:
     lines = f.readlines()
 
   HTML_TEMPLATE_REGEX = '{__html_template__}'
@@ -385,9 +385,9 @@ def _process_dom_module(js_file, html_file):
   EXPORT_LINE_REGEX = '/* #export */'
 
   # Ignore lines with an ignore annotation.
-  IGNORE_LINE_REGEX = '\s*/\* #ignore \*/(\S|\s)*'
+  IGNORE_LINE_REGEX = r'\s*/\* #ignore \*/(\S|\s)*'
 
-  with io.open(js_file, encoding='utf-8') as f:
+  with open(js_file, encoding='utf-8') as f:
     lines = f.readlines()
 
   imports_added = False
@@ -585,7 +585,7 @@ def main(argv):
   # Reconstruct file.
   # Specify the newline character so that the exact same file is generated
   # across platforms.
-  with io.open(os.path.join(out_folder, result[1]), mode='wb') as f:
+  with open(os.path.join(out_folder, result[1]), mode='wb') as f:
     for l in result[0]:
       f.write(l.encode('utf-8'))
 
diff --git a/src/3rdparty/chromium/tools/protoc_wrapper/protoc_convert.py b/src/3rdparty/chromium/tools/protoc_wrapper/protoc_convert.py
index 1da63e4..e31de31 100644
--- a/src/3rdparty/chromium/tools/protoc_wrapper/protoc_convert.py
+++ b/src/3rdparty/chromium/tools/protoc_wrapper/protoc_convert.py
@@ -19,8 +19,8 @@ def Main():
                       help='Path to output file that will be used as stdout.')
   args, passthrough_args = parser.parse_known_args()
 
-  stdin = open(args.infile, 'r')
-  stdout = open(args.outfile, 'w')
+  stdin = open(args.infile, 'r', encoding='utf-8')
+  stdout = open(args.outfile, 'w', encoding='utf-8')
 
   subprocess.check_call([args.protoc] + passthrough_args, stdin=stdin,
       stdout=stdout)
diff --git a/src/3rdparty/chromium/tools/protoc_wrapper/protoc_wrapper.py b/src/3rdparty/chromium/tools/protoc_wrapper/protoc_wrapper.py
index 94fde1e..ed2f35e 100755
--- a/src/3rdparty/chromium/tools/protoc_wrapper/protoc_wrapper.py
+++ b/src/3rdparty/chromium/tools/protoc_wrapper/protoc_wrapper.py
@@ -47,7 +47,7 @@ def WriteIncludes(headers, include):
   for filename in headers:
     include_point_found = False
     contents = []
-    with open(filename) as f:
+    with open(filename, 'r', encoding='utf-8') as f:
       for line in f:
         stripped_line = line.strip()
         contents.append(stripped_line)
@@ -62,7 +62,7 @@ def WriteIncludes(headers, include):
         raise RuntimeError("Include point not found in header: "
                            "{0} .".format(filename))
 
-    with open(filename, "w") as f:
+    with open(filename, 'w', encoding='utf-8') as f:
       for line in contents:
         print(line, file=f)
 
@@ -149,7 +149,8 @@ def main(argv):
 
   protoc_cmd += ["--proto_path", proto_dir]
   for path in options.import_dir:
-    protoc_cmd += ["--proto_path", path]
+    if os.path.exists(path):
+      protoc_cmd += ["--proto_path", path]
 
   protoc_cmd += [os.path.join(proto_dir, name) for name in protos]
 
diff --git a/src/3rdparty/chromium/tools/v8_context_snapshot/BUILD.gn b/src/3rdparty/chromium/tools/v8_context_snapshot/BUILD.gn
index c238e7e..919989a 100644
--- a/src/3rdparty/chromium/tools/v8_context_snapshot/BUILD.gn
+++ b/src/3rdparty/chromium/tools/v8_context_snapshot/BUILD.gn
@@ -94,7 +94,7 @@ if (use_v8_context_snapshot) {
   # disable it while taking a V8 snapshot.
   config("disable_icf") {
     visibility = [ ":*" ]  # Only targets in this file can depend on this.
-    if (is_win) {
+    if (is_msvc) {
       ldflags = [ "/OPT:NOICF" ]  # link.exe, but also lld-link.exe.
     } else if (use_gold || use_lld) {
       ldflags = [ "-Wl,--icf=none" ]
diff --git a/src/3rdparty/chromium/tools/win/DebugVisualizers/BUILD.gn b/src/3rdparty/chromium/tools/win/DebugVisualizers/BUILD.gn
index 3f47a77..e4328b0 100644
--- a/src/3rdparty/chromium/tools/win/DebugVisualizers/BUILD.gn
+++ b/src/3rdparty/chromium/tools/win/DebugVisualizers/BUILD.gn
@@ -20,11 +20,15 @@ assert(is_win)
 config("chrome") {
   # chrome.natvis listed as an input in //base:base to guarantee relinking on
   # changes.
-  ldflags = [ "/NATVIS:" + rebase_path(get_path_info("chrome.natvis", "abspath")) ]
+  if (is_msvc) {
+    ldflags = [ "/NATVIS:" + rebase_path(get_path_info("chrome.natvis", "abspath")) ]
+  }
 }
 
 config("blink") {
   # blink.natvis listed as an input in
   # //third_party/blink/renderer/platform/wtf to guarantee relinking on changes.
-  ldflags = [ "/NATVIS:" + rebase_path(get_path_info("blink.natvis", "abspath")) ]
+  if (is_msvc) {
+    ldflags = [ "/NATVIS:" + rebase_path(get_path_info("blink.natvis", "abspath")) ]
+  }
 }
